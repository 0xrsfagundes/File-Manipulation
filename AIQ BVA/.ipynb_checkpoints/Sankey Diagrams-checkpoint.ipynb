{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c855ff5c",
   "metadata": {},
   "source": [
    "<h2>Library</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de9b7678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34eacb5",
   "metadata": {},
   "source": [
    "<h2>Function</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "058c772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_value(value):\n",
    "    if value >= 1000000:\n",
    "        return f'{value/1000000:.1f}M'\n",
    "    elif value >= 1000:\n",
    "        return f'{value/1000:.1f}K'\n",
    "    else:\n",
    "        return f'{value:.0f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d55c706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gray_tones(num_colors):\n",
    "    # Define the range of gray values (0 = black, 255 = white)\n",
    "    min_gray = 120\n",
    "    max_gray = 220\n",
    "\n",
    "    # Calculate the step size to evenly distribute the tones\n",
    "    step = (max_gray - min_gray) // (num_colors - 1)\n",
    "\n",
    "    # Generate a list of random gray colors\n",
    "    gray_colors = []\n",
    "    for _ in range(num_colors):\n",
    "        gray_value = min_gray + step * _\n",
    "        gray_color = \"#{:02X}{:02X}{:02X}\".format(gray_value, gray_value, gray_value)\n",
    "        gray_colors.append(gray_color)\n",
    "\n",
    "    # Shuffle the list to randomize the order\n",
    "    #random.shuffle(gray_colors)\n",
    "    \n",
    "    return gray_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10343cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bu_audiencetype_vehicle_sankey_plot(df, value_column, by_Dell, title):\n",
    "    \n",
    "    if by_Dell:\n",
    "        df = df[(df['Segment ID'] != 0) & (df['Segment ID'] != '0')]\n",
    "    \n",
    "    # Get Segments Unique Counts\n",
    "    df_lvl1_seg = df.groupby(['BU'])['Segment ID'].nunique().reset_index()\n",
    "    df_lvl2_seg = df.groupby(['Audience Type'])['Segment ID'].nunique().reset_index()\n",
    "    df_lvl3_seg = df.groupby(['Display Dell Vehicle Mapped'])['Segment ID'].nunique().reset_index()\n",
    "    df_lvl1_seg.rename(columns={'BU':'Label', 'Segment ID':'Segments'}, inplace=True)\n",
    "    df_lvl2_seg.rename(columns={'Audience Type':'Label', 'Segment ID':'Segments'}, inplace=True)\n",
    "    df_lvl3_seg.rename(columns={'Display Dell Vehicle Mapped':'Label', 'Segment ID':'Segments'}, inplace=True)\n",
    "    segment_df = pd.concat([df_lvl1_seg, df_lvl2_seg,df_lvl3_seg])\n",
    "    ######\n",
    "    \n",
    "    df_lvl1 = df.groupby(['BU', 'Audience Type'])[value_column].sum().reset_index()\n",
    "    df_lvl2 = df.groupby(['Audience Type', 'Display Dell Vehicle Mapped'])[value_column].sum().reset_index()\n",
    "\n",
    "    df_lvl1['Level'] = 1\n",
    "    df_lvl2['Level'] = 2\n",
    "\n",
    "        \n",
    "    df_lvl1.rename(columns={'BU':'Source', 'Audience Type':'Target', value_column:'Value'}, inplace=True)\n",
    "    df_lvl2.rename(columns={'Audience Type':'Source', 'Display Dell Vehicle Mapped':'Target', value_column:'Value'}, inplace=True)\n",
    "\n",
    "    # Concatenate the dataframes into one\n",
    "    concat_df = pd.concat([df_lvl1[['Source', 'Target', 'Value', 'Level']],\n",
    "                           df_lvl2[['Source','Target','Value', 'Level']]],\n",
    "                          ignore_index=True)\n",
    "\n",
    "    unique_values = pd.unique(concat_df[['Source', 'Target']].values.ravel('K'))\n",
    "\n",
    "    mapping_df = pd.DataFrame({'Label': unique_values.tolist(),\n",
    "                               'Value': [i for i in range(len(unique_values))]})\n",
    "\n",
    "    # Replace values based on the mappings\n",
    "    concat_df['Source'] = concat_df['Source'].replace(mapping_df.set_index('Label')['Value'])\n",
    "    concat_df['Target'] = concat_df['Target'].replace(mapping_df.set_index('Label')['Value'])\n",
    "    \n",
    "    \n",
    "    ##########\n",
    "    level_list = concat_df['Level'].unique().tolist()\n",
    "\n",
    "    if len(level_list) > 1:\n",
    "        level_list_source = level_list[:-1]\n",
    "        level_list_target = [level_list[-1]]  # Wrap the last level in a list\n",
    "    else:\n",
    "        level_list_source, level_list_target = [1], [1]\n",
    "\n",
    "\n",
    "    df_source = concat_df[concat_df['Level'].isin(level_list_source)].groupby(['Source','Level'])['Value'].sum().reset_index()\n",
    "    total_sum_source = df_source[df_source['Level'] == level_list[0]]['Value'].sum()\n",
    "    df_source['Percentage'] = (df_source['Value'] / total_sum_source) * 100\n",
    "\n",
    "    df_target = concat_df[concat_df['Level'].isin(level_list_target)].groupby(['Target','Level'])['Value'].sum().reset_index()\n",
    "    total_sum_source = df_target[df_target['Level'].isin(level_list_target)]['Value'].sum()\n",
    "    df_target['Percentage'] = (df_target['Value'] / total_sum_source) * 100\n",
    "\n",
    "\n",
    "    df_source.rename(columns={'Value':'Total','Source':'Value'}, inplace=True)\n",
    "    df_target.rename(columns={'Value':'Total','Target':'Value'}, inplace=True)\n",
    "\n",
    "    totals_df = pd.concat([df_source, df_target])\n",
    "\n",
    "    merged_df = mapping_df.merge(totals_df, on='Value', how='left').merge(segment_df, on='Label', how='left')\n",
    "\n",
    "    merged_df['Label_x'] = merged_df['Label'] + \" (\" + merged_df['Segments'].apply(format_value) + \") \" + \"<br>\" + merged_df['Percentage'].apply(lambda x: f'{x:.1f}%')+ \" (\" + merged_df['Total'].apply(format_value) + \")\"\n",
    "    ###\n",
    "    \n",
    "\n",
    "    # Your existing data\n",
    "    source = concat_df['Source'].values.tolist()\n",
    "    target = concat_df['Target'].values.tolist()\n",
    "    value = concat_df['Value'].values.tolist()\n",
    "    labels = merged_df['Label_x'].values.tolist()\n",
    "\n",
    "    # List of colors for each link based on some condition or data\n",
    "    colors = generate_gray_tones(len(source))\n",
    "\n",
    "    # Create links with specified colors\n",
    "    link = dict(source=source, target=target, value=value, color=colors)\n",
    "\n",
    "    # Create nodes\n",
    "    node = dict(label=labels, pad=30, thickness=20)\n",
    "\n",
    "    # Create a Sankey object\n",
    "    chart = go.Sankey(link=link, node=node, arrangement=\"snap\")\n",
    "\n",
    "    # Build a figure\n",
    "    fig = go.Figure(chart)\n",
    "\n",
    "    # Add a title to the figure\n",
    "    fig.update_layout(title_text=title, width=800)\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "    \n",
    "    #html_file_path = 'html/' + title + \".html\"\n",
    "    #pio.write_html(fig, file=html_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02be49b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audiencetype_vehicles_sankey_plot(df, value_column, by_Dell, title):\n",
    "    \n",
    "    if by_Dell:\n",
    "        df = df[(df['Segment ID'] != 0) & (df['Segment ID'] != '0')]\n",
    "    \n",
    "    # Get Segments Unique Counts\n",
    "    df_lvl1_seg = df.groupby(['Audience Type'])['Segment ID'].nunique().reset_index()\n",
    "    df_lvl2_seg = df.groupby(['Display Dell Vehicle Mapped'])['Segment ID'].nunique().reset_index()\n",
    "    df_lvl1_seg.rename(columns={'Audience Type':'Label', 'Segment ID':'Segments'}, inplace=True)\n",
    "    df_lvl2_seg.rename(columns={'Display Dell Vehicle Mapped':'Label', 'Segment ID':'Segments'}, inplace=True)\n",
    "    segment_df = pd.concat([df_lvl1_seg, df_lvl2_seg])\n",
    "    ######\n",
    "\n",
    "\n",
    "    # Get Spend Sum\n",
    "    df_lvl1 = df.groupby(['Audience Type', 'Display Dell Vehicle Mapped'])[value_column].sum().reset_index()\n",
    "    df_lvl1.rename(columns={'Audience Type':'Source', 'Display Dell Vehicle Mapped':'Target', value_column:'Value'}, inplace=True)\n",
    "    unique_values = pd.unique(df_lvl1[['Source', 'Target']].values.ravel('K'))\n",
    "    mapping_df = pd.DataFrame({'Label': unique_values.tolist()\n",
    "                                              , 'Value': [i for i in range(len(unique_values))]})\n",
    "\n",
    "    # Replace values based on the mappings\n",
    "    df_lvl1['Source'] = df_lvl1['Source'].replace(mapping_df.set_index('Label')['Value'])\n",
    "    df_lvl1['Target'] = df_lvl1['Target'].replace(mapping_df.set_index('Label')['Value'])\n",
    "\n",
    "    # Contact the dataframes in just one\n",
    "    concat_df = pd.concat([\n",
    "                           df_lvl1[['Source','Target','Value']]\n",
    "                        ], ignore_index=True)\n",
    "    \n",
    "    ##########\n",
    "    df_source = concat_df.groupby('Source')['Value'].sum().reset_index()\n",
    "    total_sum_source = df_source['Value'].sum()\n",
    "    df_source['Percentage'] = (df_source['Value'] / total_sum_source) * 100\n",
    "    df_source.rename(columns={'Value':'Total','Source':'Value'}, inplace=True)\n",
    "\n",
    "    df_target = concat_df.groupby('Target')['Value'].sum().reset_index()\n",
    "    total_sum_target = df_target['Value'].sum()\n",
    "    df_target['Percentage'] = (df_target['Value'] / total_sum_target) * 100\n",
    "    df_target.rename(columns={'Value':'Total','Target':'Value'}, inplace=True)\n",
    "\n",
    "    totals_df = pd.concat([df_source, df_target])\n",
    "\n",
    "    merged_df = mapping_df.merge(totals_df, on='Value', how='left').merge(segment_df, on='Label', how='left')\n",
    "\n",
    "    merged_df['Label_x'] = merged_df['Label'] + \" (\" + merged_df['Segments'].apply(format_value) + \") \" + \"<br>\" + merged_df['Percentage'].apply(lambda x: f'{x:.1f}%')+ \" (\" + merged_df['Total'].apply(format_value) + \")\"\n",
    "    ############\n",
    "\n",
    "    \n",
    "    \n",
    "    # Sample data\n",
    "    source = df_lvl1['Source'].values.tolist()\n",
    "    target = df_lvl1['Target'].values.tolist()\n",
    "    value = df_lvl1['Value'].values.tolist()\n",
    "    labels = merged_df['Label_x'].values.tolist()\n",
    "\n",
    "    # List of colors for each link based on some condition or data\n",
    "    colors = generate_gray_tones(len(source))\n",
    "\n",
    "    # Create links\n",
    "    link = dict(source=source, target=target, value=value, color=colors)\n",
    "\n",
    "    # Create nodes\n",
    "    node = dict(label=labels, pad=30, thickness=20)\n",
    "\n",
    "    # Create a Sankey object\n",
    "    chart = go.Sankey(link=link, node=node, arrangement=\"snap\")\n",
    "\n",
    "    # Build a figure\n",
    "    fig = go.Figure(chart)\n",
    "    \n",
    "    # Add a title to the figure\n",
    "    fig.update_layout(title_text=title, width=800)\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    #html_file_path = 'html/' + title + \".html\"\n",
    "    #pio.write_html(fig, file=html_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b05270b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funnel_sankey_plot(df, value_column, by_Dell, title):\n",
    "    \n",
    "    if by_Dell:\n",
    "        df = df[(df['Segment ID'] != 0) & (df['Segment ID'] != '0')]\n",
    "    \n",
    "    # Fix issue with 'Audience Type Name': 'CRM-1PD\\xa0CRM'\n",
    "    df['Audience Type Name'] = df['Audience Type Name'].str.replace('CRM-1PD\\xa0CRM', 'CRM-1PD CRM')\n",
    "\n",
    "    # Get Segments Unique Counts\n",
    "    df_lvl1_seg = df.groupby(['Audience Type'])['Segment ID'].nunique().reset_index()\n",
    "    df_lvl2_seg = df.groupby(['Display Funnel Mapped'])['Segment ID'].nunique().reset_index()\n",
    "    df_lvl1_seg.rename(columns={'Audience Type':'Label', 'Segment ID':'Segments'}, inplace=True)\n",
    "    df_lvl2_seg.rename(columns={'Display Funnel Mapped':'Label', 'Segment ID':'Segments'}, inplace=True)\n",
    "    segment_df = pd.concat([df_lvl1_seg, df_lvl2_seg])\n",
    "    ######\n",
    "    \n",
    "    df_lvl1 = df.groupby(['Audience Type','Display Funnel Mapped'])[value_column].sum().reset_index()\n",
    "\n",
    "    # Rename columns to Source, Target & Value\n",
    "    df_lvl1.rename(columns={'Audience Type':'Source', 'Display Funnel Mapped':'Target', value_column:'Value'}, inplace=True)\n",
    "\n",
    "    # Contact the dataframes in just one\n",
    "    concat_df = pd.concat([\n",
    "                           df_lvl1[['Source','Target','Value']]\n",
    "                        ], ignore_index=True)\n",
    "\n",
    "    unique_values = pd.unique(concat_df[['Source', 'Target']].values.ravel('K'))\n",
    "    \n",
    "    mapping_df = pd.DataFrame({'Label': unique_values.tolist()\n",
    "                                          , 'Value': [i for i in range(len(unique_values))]})\n",
    "    \n",
    "    # Replace values based on the mappings\n",
    "    concat_df['Source'] = concat_df['Source'].replace(mapping_df.set_index('Label')['Value'])\n",
    "    concat_df['Target'] = concat_df['Target'].replace(mapping_df.set_index('Label')['Value'])\n",
    "\n",
    "    \n",
    "    ##########\n",
    "    df_source = concat_df.groupby('Source')['Value'].sum().reset_index()\n",
    "    total_sum_source = df_source['Value'].sum()\n",
    "    df_source['Percentage'] = (df_source['Value'] / total_sum_source) * 100\n",
    "    df_source.rename(columns={'Value':'Total','Source':'Value'}, inplace=True)\n",
    "\n",
    "    df_target = concat_df.groupby('Target')['Value'].sum().reset_index()\n",
    "    total_sum_target = df_target['Value'].sum()\n",
    "    df_target['Percentage'] = (df_target['Value'] / total_sum_target) * 100\n",
    "    df_target.rename(columns={'Value':'Total','Target':'Value'}, inplace=True)\n",
    "\n",
    "    totals_df = pd.concat([df_source, df_target])\n",
    "\n",
    "    merged_df = mapping_df.merge(totals_df, on='Value', how='left').merge(segment_df, on='Label', how='left')\n",
    "\n",
    "    merged_df['Label_x'] = merged_df['Label'] + \" (\" + merged_df['Segments'].apply(format_value) + \") \" + \"<br>\" + merged_df['Percentage'].apply(lambda x: f'{x:.1f}%')+ \" (\" + merged_df['Total'].apply(format_value) + \")\"\n",
    "    ####\n",
    "    \n",
    "    # Sample data\n",
    "    source = concat_df['Source'].values.tolist()\n",
    "    target = concat_df['Target'].values.tolist()\n",
    "    value = concat_df['Value'].values.tolist()\n",
    "    labels = merged_df['Label_x'].values.tolist()\n",
    "\n",
    "    # List of colors for each link based on some condition or data\n",
    "    colors = generate_gray_tones(len(source))\n",
    "\n",
    "    # Create links\n",
    "    link = dict(source=source, target=target, value=value, color=colors)\n",
    "\n",
    "    # Create nodes\n",
    "    node = dict(label=labels, pad=30, thickness=20)\n",
    "\n",
    "    # Create a Sankey object\n",
    "    chart = go.Sankey(link=link, node=node, arrangement=\"snap\")\n",
    "\n",
    "    # Build a figure\n",
    "    fig = go.Figure(chart)\n",
    "    \n",
    "    # Add a title to the figure\n",
    "    fig.update_layout(title_text=title, width=800)\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    #html_file_path = 'html/' + title + \".html\"\n",
    "    #pio.write_html(fig, file=html_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e61c47cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funnel_vehicle_sankey_plot(df, value_column, by_Dell, title):\n",
    "    \n",
    "    if by_Dell:\n",
    "        df = df[(df['Segment ID'] != 0) & (df['Segment ID'] != '0')]\n",
    "    \n",
    "    # Fix issue with 'Audience Type Name': 'CRM-1PD\\xa0CRM'\n",
    "    df['Audience Type Name'] = df['Audience Type Name'].str.replace('CRM-1PD\\xa0CRM', 'CRM-1PD CRM')\n",
    "\n",
    "    # Get Segments Unique Counts\n",
    "    df_lvl1_seg = df.groupby(['Audience Type'])['Segment ID'].nunique().reset_index()\n",
    "    df_lvl2_seg = df.groupby(['Display Funnel Mapped'])['Segment ID'].nunique().reset_index()\n",
    "    df_lvl3_seg = df.groupby(['Display Dell Vehicle Mapped'])['Segment ID'].nunique().reset_index()\n",
    "    df_lvl1_seg.rename(columns={'Audience Type':'Label', 'Segment ID':'Segments'}, inplace=True)\n",
    "    df_lvl2_seg.rename(columns={'Display Funnel Mapped':'Label', 'Segment ID':'Segments'}, inplace=True)\n",
    "    df_lvl3_seg.rename(columns={'Display Dell Vehicle Mapped':'Label', 'Segment ID':'Segments'}, inplace=True)\n",
    "    segment_df = pd.concat([df_lvl1_seg, df_lvl2_seg, df_lvl3_seg])\n",
    "    ######    \n",
    "    \n",
    "    df_lvl1 = df.groupby(['Audience Type','Display Funnel Mapped'])[value_column].sum().reset_index()\n",
    "    df_lvl2 = df.groupby(['Audience Type','Display Funnel Mapped','Display Dell Vehicle Mapped'])[value_column].sum().reset_index()\n",
    "    \n",
    "    df_lvl1['Level'] = 1\n",
    "    df_lvl2['Level'] = 2\n",
    "    \n",
    "    # Rename columns to Source, Target & Value\n",
    "    df_lvl1.rename(columns={'Audience Type':'Source', 'Display Funnel Mapped':'Target', value_column:'Value'}, inplace=True)\n",
    "    df_lvl2.rename(columns={'Display Funnel Mapped':'Source', 'Display Dell Vehicle Mapped':'Target', value_column:'Value'}, inplace=True)\n",
    "\n",
    "    # Contact the dataframes in just one\n",
    "    concat_df = pd.concat([\n",
    "                           df_lvl1[['Source','Target','Value']]\n",
    "                           , df_lvl2[['Source','Target','Value']]\n",
    "                        ], ignore_index=True)\n",
    "\n",
    "    unique_values = pd.unique(concat_df[['Source', 'Target']].values.ravel('K'))\n",
    "    \n",
    "    mapping_df = pd.DataFrame({'Label': unique_values.tolist()\n",
    "                                          , 'Value': [i for i in range(len(unique_values))]})\n",
    "    \n",
    "    # Replace values based on the mappings\n",
    "    concat_df['Source'] = concat_df['Source'].replace(mapping_df.set_index('Label')['Value'])\n",
    "    concat_df['Target'] = concat_df['Target'].replace(mapping_df.set_index('Label')['Value'])\n",
    "\n",
    "        \n",
    "    ##########\n",
    "    level_list = concat_df['Level'].unique().tolist()\n",
    "\n",
    "    if len(level_list) > 1:\n",
    "        level_list_source = level_list[:-1]\n",
    "        level_list_target = [level_list[-1]]  # Wrap the last level in a list\n",
    "    else:\n",
    "        level_list_source, level_list_target = [1], [1]\n",
    "\n",
    "\n",
    "    df_source = concat_df[concat_df['Level'].isin(level_list_source)].groupby(['Source','Level'])['Value'].sum().reset_index()\n",
    "    total_sum_source = df_source[df_source['Level'] == level_list[0]]['Value'].sum()\n",
    "    df_source['Percentage'] = (df_source['Value'] / total_sum_source) * 100\n",
    "\n",
    "    df_target = concat_df[concat_df['Level'].isin(level_list_target)].groupby(['Target','Level'])['Value'].sum().reset_index()\n",
    "    total_sum_source = df_target[df_target['Level'].isin(level_list_target)]['Value'].sum()\n",
    "    df_target['Percentage'] = (df_target['Value'] / total_sum_source) * 100\n",
    "\n",
    "\n",
    "    df_source.rename(columns={'Value':'Total','Source':'Value'}, inplace=True)\n",
    "    df_target.rename(columns={'Value':'Total','Target':'Value'}, inplace=True)\n",
    "\n",
    "    totals_df = pd.concat([df_source, df_target])\n",
    "\n",
    "    merged_df = mapping_df.merge(totals_df, on='Value', how='left').merge(segment_df, on='Label', how='left')\n",
    "\n",
    "    merged_df['Label_x'] = merged_df['Label'] + \" (\" + merged_df['Segments'].apply(format_value) + \") \" + \"<br>\" + merged_df['Percentage'].apply(lambda x: f'{x:.1f}%')+ \" (\" + merged_df['Total'].apply(format_value) + \")\"\n",
    "    ############\n",
    "    \n",
    "    \n",
    "    # Sample data\n",
    "    source = concat_df['Source'].values.tolist()\n",
    "    target = concat_df['Target'].values.tolist()\n",
    "    value = concat_df['Value'].values.tolist()\n",
    "    labels = merged_df['Label_x'].values.tolist()\n",
    "\n",
    "    # List of colors for each link based on some condition or data\n",
    "    colors = generate_gray_tones(len(source))\n",
    "\n",
    "    # Create links\n",
    "    link = dict(source=source, target=target, value=value, color=colors)\n",
    "\n",
    "    # Create nodes\n",
    "    node = dict(label=labels, pad=30, thickness=20)\n",
    "\n",
    "    # Create a Sankey object\n",
    "    chart = go.Sankey(link=link, node=node, arrangement=\"snap\")\n",
    "\n",
    "    # Build a figure\n",
    "    fig = go.Figure(chart)\n",
    "    \n",
    "    # Add a title to the figure\n",
    "    fig.update_layout(title_text=title, width=800)\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    #html_file_path = 'html/' + title + \".html\"\n",
    "    #pio.write_html(fig, file=html_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcb99089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_sankey_plot(df, value_column, by_Dell, title):\n",
    "    \n",
    "    if by_Dell:\n",
    "        df = df[(df['Segment ID'] != 0) & (df['Segment ID'] != '0')]\n",
    "    \n",
    "    # Fix issue with 'Audience Type Name': 'CRM-1PD\\xa0CRM'\n",
    "    df['Audience Type Name'] = df['Audience Type Name'].str.replace('CRM-1PD\\xa0CRM', 'CRM-1PD CRM')\n",
    "\n",
    "    # Get Segments Unique Counts\n",
    "    df_lvl1_seg = df.groupby(['Audience Type'])['Segment ID'].nunique().reset_index()\n",
    "    df_lvl2_seg = df.groupby(['Audience Type Name'])['Segment ID'].nunique().reset_index()\n",
    "    df_lvl3_seg = df.groupby(['Audience Source'])['Segment ID'].nunique().reset_index()\n",
    "    df_lvl4_seg = df.groupby(['Display Dell Vehicle Mapped'])['Segment ID'].nunique().reset_index()\n",
    "    df_lvl1_seg.rename(columns={'Audience Type':'Label', 'Segment ID':'Segments'}, inplace=True)\n",
    "    df_lvl2_seg.rename(columns={'Audience Type Name':'Label', 'Segment ID':'Segments'}, inplace=True)\n",
    "    df_lvl3_seg.rename(columns={'Audience Source':'Label', 'Segment ID':'Segments'}, inplace=True)\n",
    "    df_lvl4_seg.rename(columns={'Display Dell Vehicle Mapped':'Label', 'Segment ID':'Segments'}, inplace=True)\n",
    "    segment_df = pd.concat([df_lvl1_seg, df_lvl2_seg, df_lvl3_seg, df_lvl4_seg])\n",
    "    ######\n",
    "    \n",
    "    df_lvl1 = df.groupby(['Audience Type','Audience Type Name'])[value_column].sum().reset_index()\n",
    "    df_lvl2 = df.groupby(['Audience Type','Audience Type Name','Audience Source'])[value_column].sum().reset_index()\n",
    "    df_lvl3 = df.groupby(['Audience Type','Audience Type Name','Audience Source','Display Dell Vehicle Mapped'])[value_column].sum().reset_index()\n",
    "    \n",
    "    df_lvl1['Level'] = 1\n",
    "    df_lvl2['Level'] = 2\n",
    "    df_lvl3['Level'] = 3\n",
    "    \n",
    "    # Rename columns to Source, Target & Value\n",
    "    df_lvl1.rename(columns={'Audience Type':'Source', 'Audience Type Name':'Target', value_column:'Value'}, inplace=True)\n",
    "    df_lvl2.rename(columns={'Audience Type Name':'Source', 'Audience Source':'Target', value_column:'Value'}, inplace=True)\n",
    "    df_lvl3.rename(columns={'Audience Source':'Source', 'Display Dell Vehicle Mapped':'Target', value_column:'Value'}, inplace=True)\n",
    "\n",
    "    # Contact the dataframes in just one\n",
    "    concat_df = pd.concat([\n",
    "                           df_lvl1[['Source','Target','Value', 'Level']]\n",
    "                           , df_lvl2[['Source','Target','Value', 'Level']]\n",
    "                           , df_lvl3[['Source','Target','Value', 'Level']]\n",
    "                        ], ignore_index=True)\n",
    "\n",
    "    unique_values = pd.unique(concat_df[['Source', 'Target']].values.ravel('K'))\n",
    "    \n",
    "    mapping_df = pd.DataFrame({'Label': unique_values.tolist()\n",
    "                                          , 'Value': [i for i in range(len(unique_values))]})\n",
    "    \n",
    "    # Replace values based on the mappings\n",
    "    concat_df['Source'] = concat_df['Source'].replace(mapping_df.set_index('Label')['Value'])\n",
    "    concat_df['Target'] = concat_df['Target'].replace(mapping_df.set_index('Label')['Value'])\n",
    "\n",
    "    \n",
    "    ##########\n",
    "    level_list = concat_df['Level'].unique().tolist()\n",
    "\n",
    "    if len(level_list) > 1:\n",
    "        level_list_source = level_list[:-1]\n",
    "        level_list_target = [level_list[-1]]  # Wrap the last level in a list\n",
    "    else:\n",
    "        level_list_source, level_list_target = [1], [1]\n",
    "\n",
    "\n",
    "    df_source = concat_df[concat_df['Level'].isin(level_list_source)].groupby(['Source','Level'])['Value'].sum().reset_index()\n",
    "    total_sum_source = df_source[df_source['Level'] == level_list[0]]['Value'].sum()\n",
    "    df_source['Percentage'] = (df_source['Value'] / total_sum_source) * 100\n",
    "\n",
    "    df_target = concat_df[concat_df['Level'].isin(level_list_target)].groupby(['Target','Level'])['Value'].sum().reset_index()\n",
    "    total_sum_source = df_target[df_target['Level'].isin(level_list_target)]['Value'].sum()\n",
    "    df_target['Percentage'] = (df_target['Value'] / total_sum_source) * 100\n",
    "\n",
    "\n",
    "    df_source.rename(columns={'Value':'Total','Source':'Value'}, inplace=True)\n",
    "    df_target.rename(columns={'Value':'Total','Target':'Value'}, inplace=True)\n",
    "\n",
    "    totals_df = pd.concat([df_source, df_target])\n",
    "\n",
    "    merged_df = mapping_df.merge(totals_df, on='Value', how='left').merge(segment_df, on='Label', how='left')\n",
    "\n",
    "    merged_df['Label_x'] = merged_df['Label'] + \" (\" + merged_df['Segments'].apply(format_value) + \") \" + \"<br>\" + merged_df['Percentage'].apply(lambda x: f'{x:.1f}%')+ \" (\" + merged_df['Total'].apply(format_value) + \")\"\n",
    "    ############\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Sample data\n",
    "    source = concat_df['Source'].values.tolist()\n",
    "    target = concat_df['Target'].values.tolist()\n",
    "    value = concat_df['Value'].values.tolist()\n",
    "    labels = merged_df['Label_x'].values.tolist()\n",
    "\n",
    "    # List of colors for each link based on some condition or data\n",
    "    colors = generate_gray_tones(len(source))\n",
    "\n",
    "    # Create links\n",
    "    link = dict(source=source, target=target, value=value, color=colors)\n",
    "\n",
    "    # Create nodes\n",
    "    node = dict(label=labels, pad=30, thickness=20)\n",
    "\n",
    "    # Create a Sankey object\n",
    "    chart = go.Sankey(link=link, node=node, arrangement=\"snap\")\n",
    "\n",
    "    # Build a figure\n",
    "    fig = go.Figure(chart)\n",
    "    \n",
    "    # Add a title to the figure\n",
    "    fig.update_layout(title_text=title, width=800)\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    #html_file_path = 'html/' + title + \".html\"\n",
    "    #pio.write_html(fig, file=html_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9a14f8",
   "metadata": {},
   "source": [
    "<h2>Main</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "910fe657",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'C:\\Users\\Rafael_Fagundes\\Downloads\\compiled_data.csv'\n",
    "\n",
    "df = pd.read_csv(folder_path, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b065ea8",
   "metadata": {},
   "source": [
    "<h2>DataFrames</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3419720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Audience Type'] == '1PD')]\n",
    "\n",
    "csb_df = df[(df['BU'] == 'CSB')]\n",
    "\n",
    "b2b_df = df[(df['BU'] == 'B2B')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7f96330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spend or Net Rev or Segment ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74257b89",
   "metadata": {},
   "source": [
    "<h2>Bu | Type | Vehicle (by Dell)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63ac56fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert Spend, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25852\\3849487429.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbu_audiencetype_vehicle_sankey_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Spend'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BU and Type and Vehicles - Spend'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbu_audiencetype_vehicle_sankey_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Net Rev'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BU and Type and Vehicles - Revenue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25852\\375406986.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(df, value_column, by_Dell, title)\u001b[0m\n\u001b[0;32m     18\u001b[0m     }\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mconcat_dfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_cols\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mdf_level\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup_cols\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalue_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mdf_level\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Level'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0msource_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mdf_level\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0msource_col\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Source'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Target'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_column\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Value'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, level, drop, name, inplace, allow_duplicates)\u001b[0m\n\u001b[0;32m   1614\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1615\u001b[0m                     \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1617\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1618\u001b[1;33m             return df.reset_index(\n\u001b[0m\u001b[0;32m   1619\u001b[0m                 \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_duplicates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1620\u001b[0m             )\n\u001b[0;32m   1621\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[0m\n\u001b[0;32m   6205\u001b[0m                     level_values = algorithms.take(\n\u001b[0;32m   6206\u001b[0m                         \u001b[0mlevel_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_na_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6207\u001b[0m                     )\n\u001b[0;32m   6208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6209\u001b[1;33m                 new_obj.insert(\n\u001b[0m\u001b[0;32m   6210\u001b[0m                     \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6211\u001b[0m                     \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6212\u001b[0m                     \u001b[0mlevel_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   4768\u001b[0m                 \u001b[1;34m\"'self.flags.allows_duplicate_labels' is False.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4769\u001b[0m             )\n\u001b[0;32m   4770\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4771\u001b[0m             \u001b[1;31m# Should this be a different kind of error??\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4772\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"cannot insert {column}, already exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4773\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4774\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loc must be int\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot insert Spend, already exists"
     ]
    }
   ],
   "source": [
    "bu_audiencetype_vehicle_sankey_plot(df,'Spend',True, 'BU and Type and Vehicles - Spend')\n",
    "bu_audiencetype_vehicle_sankey_plot(df,'Net Rev', True, 'BU and Type and Vehicles - Revenue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ceef7f",
   "metadata": {},
   "source": [
    "<h2>Types | Vehicles</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dd48f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CSB\n",
    "audiencetype_vehicles_sankey_plot(csb_df, 'Spend', True, 'CSB Type and Vehicles - Spend')\n",
    "audiencetype_vehicles_sankey_plot(csb_df, 'Net Rev', True,'CSB Type and Vehicles - Revenue')\n",
    "\n",
    "# B2B\n",
    "audiencetype_vehicles_sankey_plot(b2b_df, 'Spend', True, 'B2B Type and Vehicles - Spend')\n",
    "audiencetype_vehicles_sankey_plot(b2b_df, 'Net Rev', True, 'B2B Type and Vehicles - Revenue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ac5ff3",
   "metadata": {},
   "source": [
    "<h2>Activation Paths (Type | Type Name | Source | Vehicle)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96d2d08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#CSB\n",
    "activation_sankey_plot(csb_df, 'Spend', True, 'CSB Activation Path - Spend')\n",
    "activation_sankey_plot(csb_df, 'Net Rev', False, 'CSB Activation Path - Revenue')\n",
    "\n",
    "#B2B\n",
    "activation_sankey_plot(b2b_df, 'Spend', True,'B2B Activation Path - Spend')\n",
    "activation_sankey_plot(b2b_df, 'Net Rev', True,'B2B Activation Path - Revenue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80b5695",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#CSB\n",
    "funnel_sankey_plot(csb_df, 'Spend', False, 'CSB Funnel - Spend')\n",
    "funnel_sankey_plot(csb_df, 'Net Rev', True,'CSB Funnel - Revenue')\n",
    "\n",
    "#B2B\n",
    "funnel_sankey_plot(b2b_df, 'Spend', True, 'B2B Funnel - Spend')\n",
    "funnel_sankey_plot(b2b_df, 'Net Rev', True,'B2B Funnel - Revenue')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
